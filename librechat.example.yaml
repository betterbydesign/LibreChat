# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.2.1

# Cache settings
cache: true

fileStrategy: "local"

# -------------------------------
# Interface (UI) preferences
# -------------------------------
interface:
  customWelcome: "Welcome to LibreChat! Enjoy your experience."
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  peoplePicker:
    users: true
    groups: true
    roles: true
  marketplace:
    use: false
  fileCitations: true

# -------------------------------
# Registration (optional example)
# -------------------------------
registration:
  socialLogins: ['github','google','discord','openid','facebook','apple','saml']
  # allowedDomains:
  #   - "example.com"
    
mcpServers:
  Context7:
    command: npx
    args:
      - -y
      - "@upstash/context7-mcp"
  desktop-commander:
    command: npx
    args:
      - "@wonderwhy-er/desktop-commander@latest"
# -------------------------------
# OCR configuration (root-level)
# Use with Agents capability "ocr"
# -------------------------------
ocr:
  # Choose one:
  # strategy: "custom_ocr"
  strategy: "mistral_ocr"
  # If using Mistral OCR:
  mistralModel: "mistral-ocr-latest"
  # If using a custom OCR service, set:
  # baseURL: "https://your-ocr.example.com/v1"
  # apiKey: "${OCR_API_KEY}"

# -------------------------------
# Endpoints
# -------------------------------
endpoints:
  # Optional: Shared settings for all endpoints
  # all:
  #   streamRate: 25
  #   titleConvo: true
  #   titleModel: "gpt-4.1-mini"

  # Built-in endpoints like openAI/anthropic are enabled via your .env.
  # You don't need to define them here unless you want to override shared settings.

  # Agents endpoint settings (MUST be nested under endpoints)
  agents:
    # Defaults to ~25; adjust as desired
    recursionLimit: 50
    maxRecursionLimit: 100
    disableBuilder: false
    # Optional relevance/citation controls (uncomment to tune)
    # maxCitations: 30
    # maxCitationsPerFile: 7
    # minRelevanceScore: 0.45
    # Capabilities: include "ocr" to enable OCR for file context
    capabilities: ["execute_code", "file_search", "actions", "tools", "ocr", "artifacts", "chain", "web_search"]
    # Optional: restrict which providers Agents can use
    # allowedProviders:
    #   - openAI
    #   - anthropic
    #   - OpenRouter   # exact name of the custom endpoint below

  # Custom endpoints list
  custom:
    # --- OpenRouter example ---
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      # Pass-through request metadata header recommended by LibreChat example
      headers:
        x-librechat-body-parentmessageid: "{{LIBRECHAT_BODY_PARENTMESSAGEID}}"
      models:
        # Let LibreChat fetch models from OpenRouter automatically
        default: ["meta-llama/llama-3-70b-instruct"]
      fetch: true
      titleConvo: true
      titleModel: "meta-llama/llama-3-70b-instruct"
      # Recommended for OpenRouter (varied stop tokens)
      dropParams: ["stop"]
      modelDisplayLabel: "OpenRouter"

    # (Optional) Example: Mistral native endpoint
    # - name: "Mistral"
    #   apiKey: "${MISTRAL_API_KEY}"
    #   baseURL: "https://api.mistral.ai/v1"
    #   models:
    #     default: ["mistral-tiny", "mistral-small", "mistral-medium"]
    #   fetch: true
    #   titleConvo: true
    #   titleModel: "mistral-tiny"
    #   # For Mistral, drop these to avoid 422 errors:
    #   dropParams: ["stop","user","frequency_penalty","presence_penalty"]
    #   modelDisplayLabel: "Mistral"

# -------------------------------
# Model Specs (curated menu)
# This creates a clean, labeled dropdown of the models you want.
# You can still expose native endpoints with `addedEndpoints` if desired.
# -------------------------------
modelSpecs:
  enforce: false         # set true to force using only these specs
  prioritize: true
  # If you ALSO want raw endpoints selectable in the header, add them here:
  # addedEndpoints:
  #   - openAI
  #   - anthropic
  # (Note: custom endpoint names are NOT valid in addedEndpoints)
  list:
    # ----- OpenAI picks -----
    - name: "openai-gpt5"
      label: "OpenAI — GPT-5"
      default: true
      preset:
        endpoint: "openAI"
        model: "gpt-5"
        temperature: 0.7

    - name: "openai-gpt5-mini"
      label: "OpenAI — GPT-5 Mini"
      preset:
        endpoint: "openAI"
        model: "gpt-5-mini"
        temperature: 0.7

    - name: "openai-gpt5-nano"
      label: "OpenAI — GPT-5 Nano"
      preset:
        endpoint: "openAI"
        model: "gpt-5-nano"
        temperature: 0.7

    - name: "openai-gpt41"
      label: "OpenAI — GPT-4.1"
      preset:
        endpoint: "openAI"
        model: "gpt-4.1"

    - name: "openai-gpt41-mini"
      label: "OpenAI — GPT-4.1 Mini"
      preset:
        endpoint: "openAI"
        model: "gpt-4.1-mini"

    - name: "openai-gpt41-nano"
      label: "OpenAI — GPT-4.1 Nano"
      preset:
        endpoint: "openAI"
        model: "gpt-4.1-nano"

    - name: "openai-o3-deep-research"
      label: "OpenAI — o3 Deep Research"
      preset:
        endpoint: "openAI"
        model: "o3-deep-research"
        # Optional: reasoning/Responses API toggles if you use them
        # useResponsesApi: true
        # reasoning_effort: "medium"

    - name: "openai-o4-mini-deep-research"
      label: "OpenAI — o4 Mini Deep Research"
      preset:
        endpoint: "openAI"
        model: "o4-mini-deep-research"

    - name: "openai-gpt-image-1"
      label: "OpenAI — GPT Image 1"
      preset:
        endpoint: "openAI"
        model: "gpt-image-1"
        imageDetail: "auto"

    # ----- Anthropic picks -----
    - name: "anthropic-claude-opus-4-1"
      label: "Anthropic — Claude Opus 4.1"
      preset:
        endpoint: "anthropic"
        model: "claude-opus-4-1"
        topP: 0.8
        temperature: 0.7

    - name: "anthropic-claude-sonnet-4-0"
      label: "Anthropic — Claude Sonnet 4.0"
      preset:
        endpoint: "anthropic"
        model: "claude-sonnet-4-0"
        topP: 0.8
        temperature: 0.7

    - name: "anthropic-claude-3-5-haiku-latest"
      label: "Anthropic — Claude 3.5 Haiku (latest)"
      preset:
        endpoint: "anthropic"
        model: "claude-3-5-haiku-latest"
        topP: 0.8
        temperature: 0.7

    # ----- OpenRouter pick (optional curated choice) -----
    - name: "openrouter-llama3-70b"
      label: "OpenRouter — Llama-3 70B Instruct"
      preset:
        # IMPORTANT: for custom endpoints, endpoint must equal the custom 'name'
        endpoint: "OpenRouter"
        model: "meta-llama/llama-3-70b-instruct"
        temperature: 0.7
